{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: John Pateros 824124958\n",
    "Date: 4/20/24 <br>\n",
    "CS 659 Assignment #4 Local Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ANMS (x , y, r, maximum):\n",
    "\n",
    "    #x is an array of length N\n",
    "    #y is an array of length N\n",
    "    #r is the cornerness score\n",
    "    #max is the number of corners that are required\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    NewList = []\n",
    "\n",
    "    while i < len(x):\n",
    "\n",
    "        minimum = 1000000000000 #random large value\n",
    "        FirstCoordinate, SecondCoordinate = x[i], y[i]\n",
    "\n",
    "        while j < len(x):\n",
    "\n",
    "            CompareCoordinate1, CompareCoordinate2 = x[j], y[j]\n",
    "            if (FirstCoordinate != CompareCoordinate1 and SecondCoordinate != CompareCoordinate2) and r[i] < r[j]:\n",
    "\n",
    "                distance = math.sqrt((CompareCoordinate1 - FirstCoordinate)**2 + (CompareCoordinate2 - SecondCoordinate)**2)\n",
    "                if distance < minimum:\n",
    "                    minimum = distance\n",
    "\n",
    "            j = j + 1\n",
    "        NewList.append([FirstCoordinate, SecondCoordinate, minimum])\n",
    "\n",
    "        i = i + 1\n",
    "        j = 0\n",
    "\n",
    "    NewList.sort(key = lambda t: t[2])\n",
    "    NewList = NewList[len(NewList)-maximum:len(NewList)]\n",
    "\n",
    "    return NewList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_interest_points(image, feature_width):\n",
    "\n",
    "    alpha = 0.04\n",
    "    threshold = 10000 # minimal value of Harris Score. Any points scored less than this threshold should be removed. \n",
    "\n",
    "    \n",
    "    XCorners = [] # X-coordinate\n",
    "    YCorners = [] # Y-coordinate\n",
    "    RValues = []  # Cornerness value\n",
    "\n",
    "    #Compute the size of the image.\n",
    "\n",
    "    ImageRows = image.shape[0]\n",
    "    ImageColumns = image.shape[1]\n",
    "\n",
    "    #Use the soble filter to calculate the x and y derivative of the image. You might use the cv2.Sobel() as follows.\n",
    "\n",
    "\n",
    "    Xderivative = cv2.Sobel(image, cv2.CV_64F,1,0,ksize=5)\n",
    "    Yderivative = cv2.Sobel(image, cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "\n",
    "    #Define matrices Ixx, Iyy and Ixy\n",
    "\n",
    "    Ixx = (Xderivative)*(Xderivative)\n",
    "    Iyy = (Yderivative)*(Yderivative)\n",
    "    Ixy = (Xderivative)*(Yderivative)\n",
    "\n",
    "    filter1 = cv2.getGaussianKernel(ksize=4, sigma=2)\n",
    "    Ixx = cv2.filter2D(Ixx, -1, filter1)\n",
    "    Iyy = cv2.filter2D(Iyy, -1, filter1)\n",
    "    Ixy = cv2.filter2D(Ixy, -1, filter1)\n",
    "\n",
    "    #loop over the image to compute cornerness score of each pixel\n",
    "    \n",
    "    for i in range(ImageRows):\n",
    "        for j in range(ImageColumns):\n",
    "            score = Ixx[i][j]*Iyy[i][j] - (Ixy[i][j]**2) - (alpha * (Ixx[i][j]+Iyy[i][j])**2)\n",
    "            if score >= threshold:\n",
    "                XCorners.append(j)\n",
    "                YCorners.append(i)\n",
    "                RValues.append(score)\n",
    "\n",
    "    XCorners = np.asarray(XCorners)\n",
    "    YCorners = np.asarray(YCorners)\n",
    "    RValues = np.asarray(RValues)\n",
    "\n",
    "    #Use ANMS to evenly distribute the corners in the image.\n",
    "\n",
    "    NewCorners = ANMS(XCorners, YCorners, RValues, 3025)\n",
    "\n",
    "    NewCorners = np.asarray(NewCorners)\n",
    "\n",
    "\n",
    "    #Return the x-y coordinates and cornerness score of the eligible corners.\n",
    "\n",
    "    x = NewCorners[:,0]\n",
    "    y = NewCorners[:,1]\n",
    "    scales = NewCorners[:,2]\n",
    "\n",
    "\n",
    "    return x,y, scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = load_image('data/Notre Dame/A.jpg')\n",
    "image2 = load_image('data/Notre Dame/B.jpg')\n",
    "eval_file = '../data/Notre Dame/A_to_B.pkl'\n",
    "\n",
    "\n",
    "scale_factor = 0.5\n",
    "image1 = cv2.resize(image1, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "image2 = cv2.resize(image2, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "image1_bw = cv2.cvtColor(image1, cv2.COLOR_RGB2GRAY)\n",
    "image2_bw = cv2.cvtColor(image2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "feature_width = 16 # width and height of each local feature, in pixels. \n",
    "########## interest point detection ##########\n",
    "print('get_interest_points()...image 1')\n",
    "x1, y1, scales1= get_interest_points(image1_bw, feature_width)\n",
    "print('get_interest_points()... image 2')\n",
    "x2, y2, scales2 = get_interest_points(image2_bw, feature_width)\n",
    "\n",
    "print('visualizing the interest points')\n",
    "# Visualize the interest points\n",
    "c1 = show_interest_points(image1, x1, y1)\n",
    "c2 = show_interest_points(image2, x2, y2)\n",
    "plt.figure(); plt.imshow(c1)\n",
    "plt.figure(); plt.imshow(c2)\n",
    "print('{:d} corners in image 1, {:d} corners in image 2'.format(len(x1), len(x2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncomaptibleWindowSizes(Exception):\n",
    "    pass\n",
    "\n",
    "#tunable parameters for the ablasian study\n",
    "bins = 8\n",
    "mainWindowSize = 8\n",
    "smallerWindowSize = 4\n",
    "#options in the future: padding type, \n",
    "\n",
    "#calculations based on tunables\n",
    "halfmainWindowSize = mainWindowSize // 2\n",
    "numRegions = (mainWindowSize // smallerWindowSize) ** 2\n",
    "numRegionsAcross = int(math.sqrt(numRegions))\n",
    "\n",
    "print(numRegions)\n",
    "print(numRegionsAcross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features(image, x, y, feature_width):\n",
    "    # the goal of this function is to extract a feature vector for each interest point\n",
    "    \n",
    "  #Round off the x and y coordinates to integers.\n",
    "\n",
    "  x = np.rint(x)\n",
    "  x = x.astype(int)\n",
    "  y = np.rint(y)\n",
    "  y = y.astype(int)\n",
    "\n",
    "  #Define a gaussian filter.\n",
    "\n",
    "  cutoff_frequency = 10\n",
    "\n",
    "  filter1 = cv2.getGaussianKernel(ksize=4,sigma=cutoff_frequency)\n",
    "  filter1 = np.dot(filter1, filter1.T)\n",
    "\n",
    "  #Apply the gaussian filter to the image.\n",
    "\n",
    "  image = cv2.filter2D(image, -1, filter1)\n",
    "  ImageRows = image.shape[0]\n",
    "  ImageColumns = image.shape[1]\n",
    "\n",
    "  Xcoordinates = len(x)\n",
    "  Ycoordinates = len(y)\n",
    "\n",
    "  #pad image to prevent out of bounds error can play with how we pad it \n",
    "  padSize = halfmainWindowSize\n",
    "  image = np.pad(image, padSize, mode='edge')\n",
    "\n",
    "\n",
    "  if (mainWindowSize % smallerWindowSize != 0):\n",
    "    # Raise the exception\n",
    "    raise IncomaptibleWindowSizes(\"Incompatible large and small window sizes \")\n",
    "\n",
    "  dim = numRegions * bins;  # feature dimension\n",
    "\n",
    "  FeatureVectorIn = np.ones((Xcoordinates,dim)) # each row represents a vector of dim. \n",
    "  NormalizedFeature = np.zeros((Xcoordinates,dim))\n",
    "\n",
    "\n",
    "  #loop over the corners generated by Harris\n",
    "\n",
    "  for i in range(Xcoordinates):\n",
    "\n",
    "    #Extract a 16X16 window centered at the corner pixel\n",
    "    temp1 = int(x[i]) + padSize\n",
    "    temp2 = int(y[i]) + padSize\n",
    "    Window = image[temp2 -  halfmainWindowSize:temp2 + halfmainWindowSize, temp1 - halfmainWindowSize:temp1 + halfmainWindowSize]\n",
    "    \n",
    "    # write your own code to extract the feature vectors FeatureVectorIn for this 16 by 16 window. \n",
    "    gradient_base_orientations = np.gradient(Window)\n",
    "    gradient_magnitudes = np.sqrt(gradient_base_orientations[0]**2 + gradient_base_orientations[1]**2)\n",
    "    gradient_angles = np.rad2deg(np.mod(np.arctan2(gradient_base_orientations[0], gradient_base_orientations[1]), 2*np.pi)).astype('uint32')\n",
    "    complete_feature_vector = np.zeros((numRegionsAcross, numRegionsAcross, bins))\n",
    "    \n",
    "    angle_floor = 360 // bins\n",
    "    for j in range(Window.shape[0]):\n",
    "      for k in range(Window.shape[0]):\n",
    "        vector_y = j // (mainWindowSize // numRegionsAcross)\n",
    "        vector_x = k // (mainWindowSize // numRegionsAcross)\n",
    "        or_index = (gradient_angles[j][k]-1) // angle_floor\n",
    "        \n",
    "        if(or_index < (bins - 1)):\n",
    "          weight_r = (gradient_angles[j][k] % angle_floor) / angle_floor\n",
    "          weight_l = (angle_floor - (gradient_angles[j][k] % angle_floor)) / angle_floor\n",
    "          complete_feature_vector[vector_y, vector_x, or_index] += weight_l * gradient_magnitudes[j][k]\n",
    "          complete_feature_vector[vector_y,vector_x, or_index+1] += weight_r * gradient_magnitudes[j][k]\n",
    "        else:\n",
    "          complete_feature_vector[vector_y,vector_x, or_index] += gradient_magnitudes[j][k]\n",
    "\n",
    "    FeatureVectorIn[i] = complete_feature_vector.flatten()\n",
    "\n",
    "    #Write your code to normalize the generated feature vector\n",
    "    NormalizedFeature[i] = FeatureVectorIn[i]/np.linalg.norm(FeatureVectorIn[i],1)\n",
    "    NormalizedFeature[i] = np.clip(FeatureVectorIn[i],0,0.2)\n",
    "    NormalizedFeature[i] = NormalizedFeature[i]/np.linalg.norm(NormalizedFeature[i],1)\n",
    "\n",
    "  #Return normalized feature vector\n",
    "  fv = NormalizedFeature\n",
    "  return fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Extract feature descriptors ########\n",
    "image1_features = get_features(image1_bw, x1, y1, feature_width)\n",
    "image2_features = get_features(image2_bw, x2, y2, feature_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_distance(hist1, hist2):\n",
    "    #histogram Eucleidan distance calcualtion\n",
    "    squared_diff = (hist1 - hist2) ** 2\n",
    "    sum_squared_diff = np.sum(squared_diff)\n",
    "    euclidean_distance = np.sqrt(sum_squared_diff)\n",
    "    \n",
    "    return euclidean_distance\n",
    "\n",
    "\n",
    "def match_features(features1, features2, x1, y1, x2, y2):\n",
    "\n",
    "    Distance = np.zeros((features1.shape[0], features2.shape[0])) # Euclidean distance. \n",
    "    Value = [] # distance of matched feature\n",
    "    Hitx = [] # x-coordinate of matched feature\n",
    "    Hity = [] # y-coordinate of matched feature\n",
    "\n",
    "    #loop over the features1, write your code to find the matched feature in features 2 that has minimal disance. \n",
    "    for i in range(features1.shape[0]):\n",
    "        for j in range(features2.shape[0]):\n",
    "            sum_equils = 0\n",
    "            for k in range(mainWindowSize):\n",
    "                hist_index = k * bins\n",
    "                sum_equils += compute_euclidean_distance(features1[i,hist_index:hist_index + bins],features2[j,hist_index:hist_index + bins])\n",
    "            Distance[i][j] = sum_equils / numRegions\n",
    "\n",
    "    \n",
    "    for i in range(features1.shape[0]):\n",
    "        index = np.argmin(Distance[i])\n",
    "        Value.append(np.min(Distance[i]))\n",
    "        Hitx.append(i)\n",
    "        Hity.append(index)\n",
    "\n",
    "\n",
    "    # convert to Numpy Array. \n",
    "    Xposition = np.asarray(Hitx).astype('int32')\n",
    "    Yposition = np.asarray(Hity).astype('int32')\n",
    "    matches = np.stack((Xposition,Yposition), axis = -1)\n",
    "    confidences = np.asarray(Value)\n",
    "\n",
    "    sorted_indices = np.argsort(confidences)\n",
    "    matches = matches[sorted_indices]\n",
    "    confidences = confidences[sorted_indices]\n",
    "\n",
    "    return matches, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###Matching features over images\n",
    "matches, confidences = match_features(image1_features, image2_features, x1, y1, x2, y2)\n",
    "print('{:d} matches from {:d} corners'.format(len(matches), len(x1)))\n",
    "\n",
    "########visualization ########\n",
    "matches = np.round(matches).astype(int)\n",
    "# num_pts_to_visualize = len(matches)\n",
    "num_pts_to_visualize = 100\n",
    "c1 = show_correspondence_circles(image1, image2,\n",
    "                    x1[matches[:num_pts_to_visualize, 0]], y1[matches[:num_pts_to_visualize, 0]],\n",
    "                    x2[matches[:num_pts_to_visualize, 1]], y2[matches[:num_pts_to_visualize, 1]])\n",
    "plt.figure(); plt.imshow(c1)\n",
    "plt.savefig('../results/vis_circles_ND.jpg', dpi=1000)\n",
    "c2 = show_correspondence_lines(image1, image2,\n",
    "                    x1[matches[:num_pts_to_visualize, 0]], y1[matches[:num_pts_to_visualize, 0]],\n",
    "                    x2[matches[:num_pts_to_visualize, 1]], y2[matches[:num_pts_to_visualize, 1]])\n",
    "plt.figure(); plt.imshow(c2)\n",
    "plt.savefig('../results/vis_lines_ND.jpg', dpi=1000)\n",
    "\n",
    "### when the groundtruth correspondences are available \n",
    "\n",
    "# num_pts_to_evaluate = len(matches)\n",
    "num_pts_to_evaluate = 100\n",
    "_, c = evaluate_correspondence(image1, image2, eval_file, scale_factor,\n",
    "                        x1[matches[:num_pts_to_evaluate, 0]], y1[matches[:num_pts_to_evaluate, 0]],\n",
    "                        x2[matches[:num_pts_to_evaluate, 1]], y2[matches[:num_pts_to_evaluate, 1]])\n",
    "plt.figure(); plt.imshow(c)\n",
    "plt.savefig('../results/eval_ND.jpg', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_translations(matches, x1, y1, x2, y2):\n",
    "    tx = []\n",
    "    ty = []\n",
    "    rots = []\n",
    "    for match in matches:\n",
    "        im1_index = match[0]\n",
    "        im2_index = match[1]\n",
    "\n",
    "        x = x1[im1_index]\n",
    "        y = y1[im1_index] \n",
    "\n",
    "        x_prime = x2[im2_index]\n",
    "        y_prime = y2[im2_index]\n",
    "\n",
    "        tx.append(x_prime - x)\n",
    "        ty.append(y_prime - y)\n",
    "        theta = math.atan2(y_prime - y, x_prime - x)\n",
    "        rots.append(theta)\n",
    "\n",
    "    tx = np.asarray(tx).astype(int)\n",
    "    ty = np.asarray(ty).astype(int)\n",
    "    trans = np.stack((tx,ty), axis = -1)\n",
    "    \n",
    "    return trans, rots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans, rots = calculate_translations(matches[:num_pts_to_visualize], x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_depth(matches, x1, x2, f, t):\n",
    "    depths = []\n",
    "    for match in matches:\n",
    "        im1_index = match[0]\n",
    "        im2_index = match[1]\n",
    "        x_l = x1[im1_index]\n",
    "        x_r = x2[im2_index]\n",
    "        depth = f * (t / (x_l-x_r))\n",
    "        depths.append(abs(depth))\n",
    "\n",
    "    return depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov = 71.91\n",
    "focal_length = (image1.shape[1] * 0.5) / np.tan(fov * 0.5 * math.pi / 180) \n",
    "print(focal_length)\n",
    "print(calculate_depth(matches[:num_pts_to_visualize], x1, x2, focal_length, 27.9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
